{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81e09857-57bf-4dcf-9968-fd439fdd8ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8f33fa-48d2-4ae7-b9ed-6c3208deda1e",
   "metadata": {},
   "source": [
    "# DICE evaluation metric\n",
    "In the lab semantic segmentation, you have implemented IOU to evaluate the performance of the model. Here, you need to implement a similar evaluation metric called DICE or Sørensen–Dice coefficient, and it is formulated as: $$ DICE(X, X_{truth}) = \\frac{2|X \\cap X_{truth}|}{|X| + |X_{truth}|}$$ \\\n",
    "Compared to IOU, DICE is more sensitive to small differences in overlap due to the squared terms in the numerator and denominator, so it can be more informative when there's a need to discriminate between segmentations with subtle differences in overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ba67de8-cad4-4620-afc8-40f897b4d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DICE(inp : Tensor, tgt : Tensor):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        inp: Predicted mask (batchsize, number of classes, width, height)\n",
    "        tgt: Ground truth mask (batchsize, number of classes, width, height)\n",
    "    Returns:\n",
    "        Classwise Average of DICE coefficient\n",
    "    \"\"\"\n",
    "    eps = 1e-5 # small number to add to denominator to avoid division by zero\n",
    "    #YOUR CODE START HERE\n",
    "    sum_dim = (-1, -2, -3)\n",
    "    # calculation of intersection   \n",
    "    inter = 2 *(inp * tgt).sum(dim=sum_dim)\n",
    "\n",
    "    # calculate the sum of |inp| + |tgt|\n",
    "    sets_sum = inp.sum(dim=sum_dim) + tgt.sum(dim=sum_dim)\n",
    "    sets_sum = torch.where(sets_sum == 0, inter, sets_sum)\n",
    "\n",
    "    # calcaute the dice    \n",
    "    dice = (inter + eps) / (sets_sum + eps)\n",
    "    \n",
    "    # average the dice batchwise\n",
    "    return dice.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e549bf-b9d9-4937-a364-d2252338df8e",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee88cf73-b96f-425b-bda1-c8d693b2ee97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "prediction1 = Tensor([[0, 7, 5, 7, 2],\n",
    "        [2, 4, 5, 9, 9],\n",
    "        [2, 8, 5, 1, 8],\n",
    "        [3, 6, 5, 2, 6],\n",
    "        [3, 2, 9, 1, 1]]).unsqueeze(0).long()\n",
    "mask1 = Tensor([[4, 2, 5, 0, 2],\n",
    "        [8, 2, 9, 8, 5],\n",
    "        [0, 8, 7, 9, 6],\n",
    "        [8, 6, 5, 9, 1],\n",
    "        [3, 2, 9, 0, 6]]).unsqueeze(0).long()\n",
    "prediction2 = Tensor([[5, 7, 3, 3, 0],\n",
    "        [0, 2, 8, 2, 7],\n",
    "        [1, 7, 0, 9, 9],\n",
    "        [7, 5, 2, 3, 4],\n",
    "        [6, 0, 9, 0, 1]]).unsqueeze(0).long()\n",
    "mask2 = Tensor([[4, 6, 8, 3, 0],\n",
    "        [4, 4, 7, 2, 7],\n",
    "        [0, 0, 4, 9, 9],\n",
    "        [5, 2, 3, 3, 4],\n",
    "        [3, 0, 0, 8, 2]]).unsqueeze(0).long()\n",
    "\n",
    "#Tests\n",
    "dice1 = DICE(F.one_hot(prediction1).permute(0, 3, 1, 2).float(), F.one_hot(mask1).permute(0, 3, 1, 2).float()).item()\n",
    "dice2 = DICE(F.one_hot(prediction2).permute(0, 3, 1, 2).float(), F.one_hot(mask2).permute(0, 3, 1, 2).float()).item()\n",
    "\n",
    "assert np.isclose(0.3200001120567322, dice1), 'incorrect dice 1!'\n",
    "assert np.isclose(0.3600001037120819, dice2), 'incorrect dice 2!'\n",
    "print(\"\\033[92m All tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da69bb65-7db7-4b79-8a13-8d1d85a994fe",
   "metadata": {},
   "source": [
    "## Open questions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90afc2aa-d450-4057-8fc0-52e2fd400e65",
   "metadata": {},
   "source": [
    "1. Based on their formulation, what are the **difference** among Cross-entropy, DICE, and IOU?  \n",
    "\n",
    "Let us first consider cross-entropy and DICE. Here is a formlation for cross-entropy:\n",
    "\n",
    "$L=-\\sum^n_{i=1}{t_i \\log{p_i}}$\n",
    "\n",
    "This is for all n classes where $p_i$ is taken as a softmax probability for the $i^{th}$ class. Under the guise of semantic segmentation this cross-entropy loss would be performed as the expectation of each pixel and so no generalisation takes place. In other words, each loss is computed individually per pixel, and so there is no consideration of adjacent pixels and whether boundaries occur at these adjacent points. On the other hand both DICE and IOU both evalaute on a more granular level as they both take the sums of some form of overlap. IOU takes the area of intersection over the area of union whearas DICE takes the area of overlap over the total area. DICE also uses the square of these values and so DICE is more sensitive to smaller changes and so provides a more discrimatory loss than IOU.\n",
    "\n",
    "2. How might the choice of architecture, such as U-Net or FFN, affect the performance and application suitability of your semantic segmentation model?\n",
    "\n",
    "The choice of architecture has an immense effect on both performance and application suitability. However, models are in development that attempt to achieve greater robustness to unseen data. U-Net is an example of a convolution network with an encoder, decoder style model. This allows the model to achieves rapid learning over a quick period of time but is unstable in the long run with a particular emphasis on not being able to boundaries are intricate or when the class target is small (https://arxiv.org/abs/2309.13013#:~:text=The%20findings%20reveal%20that%20the,when%20handling%20fine%20image%20details). This suggests that the model places more effort into acheiving a greater semantic understanding of the scene rather than on the precision of a task. As such it may be more suitable for larger scale tasks than the biomedical task being investigated.\n",
    "\n",
    "As such the choice in architecture is indivitive of the task that is chosen as the problem. If precise boundaries are required a greater emphasis may be placed in having smaller convolutions and with little reduction in hidden layer size or with additional layers such that precise boundaries are retained. For over tasks, such as for RGB cameras w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba074cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:diss]",
   "language": "python",
   "name": "conda-env-diss-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
